# name: Scrape latest data
on:
 workflow_dispatch:
 schedule:
   - cron:  '0 17 * * *'

permissions:
  contents: write
  packages: write
  pull-requests: write

jobs:
 scrape:
   runs-on: ubuntu-latest
   steps:
   # Step 1: Prepare the environment
   - name: Check out this repo
     uses: actions/checkout@v2
     with:
       fetch-depth: 0
       
   # Step 2: Install requirements, so Python script can run
   - name: Install requirements
     # this may change depending on how we handle dependencies
     run: pip install -r requirements.txt

   # Step 3   
   - name: Run scraper

  # Optional: If you are publishing to Google sheets, uncomment these next 2 lines
     #env: 
      #GOOGLE_SECRET_KEY: ${{ secrets.GOOGLE_SECRET_KEY }}

     run: python open_fec_scraper.py
     env: 
       OPENFEC_API_KEY: ${{ secrets.OPENFEC_API_KEY }}

   # Step 4
   - name: Compute Party Overlaps
     run: python fec_data_merge_comm.py -l # need the -l flag to write out the report file.
     env: 
       OPENFEC_API_KEY: ${{ secrets.OPENFEC_API_KEY }}

   # Step 5
   - name: Compute Candidate Overlaps
     run: python fec_data_merge_party.py

   # Step 6
   - name: Plot top contributors, recipients
     run: python plot_fec_data.py

   # Step 7   
   - name: Commit files
     run: |
       git config remote.origin.url https://github.com/m-nolan/sunlight_fec.git
       git config --global user.name "$(git --no-pager log --format=format:'%an' -n 1)"
       git config --global user.email "$(git --no-pager log --format=format:'%ae' -n 1)"
       git add data/*.csv
       git add data/*.md
       git add figures/*.png
       git commit -m "Automated commit from GitHub Actions" || exit 0
       git pull
       git push 
